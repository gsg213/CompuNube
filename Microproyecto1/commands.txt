######  Configuring first Machine ######
# Install lxd
sudo snap install lxd
# Adding lxd group
newgrp lxd
# init lxd
lxd init
# Print certificate 
lxc info

Would you like to use LXD clustering? (yes/no) [default=no]: yes
What name should be used to identify this node in the cluster? [default=vagrantVM1]: 
What IP address or DNS name should be used to reach this node? [default=10.0.2.15]: 192.168.100.4
Are you joining an existing cluster? (yes/no) [default=no]: no
Setup password authentication on the cluster? (yes/no) [default=yes]: yes
Trust password for new clients: 
Again: 
Do you want to configure a new local storage pool? (yes/no) [default=yes]: yes
Name of the storage backend to use (btrfs, dir, lvm) [default=btrfs]: dir
Do you want to configure a new remote storage pool? (yes/no) [default=no]: no
Would you like to connect to a MAAS server? (yes/no) [default=no]: no
Would you like to configure LXD to use an existing bridge or host interface? (yes/no) [default=no]: no
Would you like to create a new Fan overlay network? (yes/no) [default=yes]: yes
What subnet should be used as the Fan underlay? [default=auto]: 
Would you like stale cached images to be updated automatically? (yes/no) [default=yes] yes
Would you like a YAML "lxd init" preseed to be printed? (yes/no) [default=no]: yes

######  Configuring second Machine ######
# Install lxd
sudo snap install lxd
# Adding lxd group
newgrp lxd
# init lxd
sudo lxd init

Would you like to use LXD clustering? (yes/no) [default=no]: yes
What name should be used to identify this node in the cluster? [default=vagrantVM2]: 
What IP address or DNS name should be used to reach this node? [default=10.0.2.15]: 192.168.100.2
Are you joining an existing cluster? (yes/no) [default=no]: yes
IP address or FQDN of an existing cluster node: 192.168.100.4
Cluster fingerprint: a3ceb39f679039fbe05ed1a24d684875acd4004c39311d534390fa83622bb732
You can validate this fingerprint by running "lxc info" locally on an existing node.
Is this the correct fingerprint? (yes/no) [default=no]: yes
Cluster trust password: 
All existing data is lost when joining a cluster, continue? (yes/no) [default=no] yes
Choose "source" property for storage pool "local": 
Would you like a YAML "lxd init" preseed to be printed? (yes/no) [default=no]: yes

######  Configuring third Machine ######
# Install lxd
sudo snap install lxd
# Adding lxd group
newgrp lxd
# init lxd
sudo lxd init

vagrant@vagrantVM3:~$ sudo lxd init
Would you like to use LXD clustering? (yes/no) [default=no]: yes
What name should be used to identify this node in the cluster? [default=vagrantVM3]: 
What IP address or DNS name should be used to reach this node? [default=10.0.2.15]: 192.168.100.3
Are you joining an existing cluster? (yes/no) [default=no]: yes
IP address or FQDN of an existing cluster node: 192.168.100.4
Cluster fingerprint: a3ceb39f679039fbe05ed1a24d684875acd4004c39311d534390fa83622bb732
You can validate this fingerprint by running "lxc info" locally on an existing node.
Is this the correct fingerprint? (yes/no) [default=no]: yes
Cluster trust password: 
All existing data is lost when joining a cluster, continue? (yes/no) [default=no] yes
Choose "source" property for storage pool "local": 
Would you like a YAML "lxd init" preseed to be printed? (yes/no) [default=no]: yes

### Video 2 ####
# Checking node's clusters
lxc cluster show vagrantVM3
# Creating a container from different machines
lxc launch ubuntu:18.04 web${MACHINEID} --target vagrantVM2

# Fast testing
lxc launch ubuntu:18.04 haproxy
lxc launch ubuntu:18.04 web1
lxc launch ubuntu:18.04 web2

lxc network list
lxc network show lxdfan0
lxc network edit lxdfan0

# Configuring certificate
sed ':a;N;$!ba;s/\n/\n    /g;s/^/    /g' certificate.txt > certificate_good.txt
sed -n -i -e '/server_address: 192.168.100.2:8443/r certificate_good.txt' -e 1x -e '2,${x;p}' -e '${x;p}' proceed_2.yaml

lxc stop web1
lxc network attach lxdbr0 web1 eth0 eth0
lxc config device set web1 eth0 ipv4.address 240.4.0.105
lxc start web1

At the end run...

lxc exec haproxy -- systemctl reload haproxy